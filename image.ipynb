{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i use 100 data to reduce the memory, due to my slow computer ^^'\n",
    "original_training_path = './cat_dog/training_set'\n",
    "original_test_set  = './cat_dog/test_set'\n",
    "\n",
    "# List all files in the original training directory\n",
    "random_files_training = [os.path.join(dp, f) for dp, dn, filenames in os.walk(original_training_path) for f in filenames if os.path.splitext(f)[1].lower() in ['.png', '.jpg', '.jpeg']]\n",
    "random_files_training = shuffle(random_files_training)  # Shuffle the list\n",
    "\n",
    "random_files_test = [os.path.join(dp, f) for dp, dn, filenames in os.walk(original_test_set) for f in filenames if os.path.splitext(f)[1].lower() in ['.png', '.jpg', '.jpeg']]\n",
    "random_files_test = shuffle(random_files_test)\n",
    "\n",
    "\n",
    "# Select the first 100 files\n",
    "random_training_set = random_files_training[:100]\n",
    "random_test_set = random_files_test[:100]\n",
    "\n",
    "# Assuming labels are defined by directory names\n",
    "labels_training_set = [os.path.basename(os.path.dirname(file)) for file in random_training_set]\n",
    "labels_test_set = [os.path.basename(os.path.dirname(file)) for file in random_test_set]\n",
    "\n",
    "# Create a DataFrame\n",
    "df_training_set = pd.DataFrame({'filename': random_training_set, 'class': labels_training_set})\n",
    "df_test_set = pd.DataFrame({'filename': random_test_set, 'class': labels_test_set})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    filename class\n",
      "0   ./cat_dog/training_set/dogs/dog.3066.jpg  dogs\n",
      "1   ./cat_dog/training_set/cats/cat.1223.jpg  cats\n",
      "2   ./cat_dog/training_set/cats/cat.1208.jpg  cats\n",
      "3    ./cat_dog/training_set/cats/cat.978.jpg  cats\n",
      "4   ./cat_dog/training_set/cats/cat.1541.jpg  cats\n",
      "..                                       ...   ...\n",
      "95  ./cat_dog/training_set/cats/cat.3501.jpg  cats\n",
      "96  ./cat_dog/training_set/cats/cat.1036.jpg  cats\n",
      "97  ./cat_dog/training_set/dogs/dog.1002.jpg  dogs\n",
      "98  ./cat_dog/training_set/cats/cat.2027.jpg  cats\n",
      "99  ./cat_dog/training_set/cats/cat.3280.jpg  cats\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 validated image filenames belonging to 2 classes.\n",
      "Found 100 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_training_set,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    subset='training',  # Use 'training' subset\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_test_set,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=10,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_43 (Conv2D)          (None, 150, 150, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 75, 75, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 37, 37, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 87616)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 87617     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,433\n",
      "Trainable params: 106,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(img_height, img_width, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 09:19:01.220832: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 1.2065 - accuracy: 0.4800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 09:19:03.497075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 435ms/step - loss: 1.2065 - accuracy: 0.4800 - val_loss: 0.9272 - val_accuracy: 0.4800\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 0.7556 - accuracy: 0.5200 - val_loss: 0.6924 - val_accuracy: 0.5300\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.6684 - accuracy: 0.6600 - val_loss: 0.6935 - val_accuracy: 0.5200\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.6499 - accuracy: 0.6700 - val_loss: 0.6954 - val_accuracy: 0.5300\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 345ms/step - loss: 0.6425 - accuracy: 0.5900 - val_loss: 0.6876 - val_accuracy: 0.5200\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 0.6043 - accuracy: 0.7000 - val_loss: 0.6891 - val_accuracy: 0.5100\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 417ms/step - loss: 0.5674 - accuracy: 0.9000 - val_loss: 0.6910 - val_accuracy: 0.5200\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 324ms/step - loss: 0.5421 - accuracy: 0.8800 - val_loss: 0.6964 - val_accuracy: 0.5200\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 329ms/step - loss: 0.4923 - accuracy: 0.8700 - val_loss: 0.7199 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 346ms/step - loss: 0.4480 - accuracy: 0.8400 - val_loss: 0.7886 - val_accuracy: 0.5300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b06fc70>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/10 [========>.....................] - ETA: 0s - loss: 0.7221 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 09:19:47.087636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 34ms/step - loss: 0.7886 - accuracy: 0.5300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7885962724685669, 0.5299999713897705]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "img_path = './cat_dog/test_set/dogs/dog.4004.jpg'\n",
    "img = load_img(img_path, target_size=(150, 150), color_mode='grayscale')\n",
    "\n",
    "# Convert the image to an array\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "# Scale the image\n",
    "img_array /= 255.0\n",
    "\n",
    "# Expand dimensions to fit the model input\n",
    "img_array = np.expand_dims(img_array, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step\n",
      "Predicted Probability: [[0.8420747]]\n",
      "Predicted Class: dog\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_array)\n",
    "print(\"Predicted Probability:\", prediction)\n",
    "\n",
    "print(prediction)\n",
    "# To get a class label, you might threshold the probability at 0.5 (adjust based on your use case)\n",
    "predicted_class = 'dog' if prediction[0][0] > 0.5 else 'cat'\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
